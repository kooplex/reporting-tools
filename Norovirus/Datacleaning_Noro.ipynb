{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import pivottablejs\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File metadata/noronet_metadata.csv does not exist: 'metadata/noronet_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2835b8952caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#df = pd.read_csv('metadata/Results-20180101.csv', low_memory=False, sep=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata/noronet_metadata.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, index_col=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File metadata/noronet_metadata.csv does not exist: 'metadata/noronet_metadata.csv'"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('metadata/Results-20180101.csv', low_memory=False, sep=',')\n",
    "df = pd.read_csv('metadata/noronet_metadata.csv', low_memory=False, sep=',')#, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(HTML(df.head().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for multiple information stored in a column\n",
    "list(df['Genus / Genogroup'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should group sequences based on their Genogroups, and there are 4 columns for this info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "for i in range(1,5):\n",
    "    s = s.union(set(df['seq %d: Genus / Genogroup'%i].unique()))\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown entries and Sapovirus are not useful so we remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_genogroups = list(s)\n",
    "available_genogroups.remove(np.nan)\n",
    "available_genogroups.remove('Unassigned')\n",
    "available_genogroups.remove('Caliciviridae Sapovirus GI')\n",
    "available_genogroups.remove('Caliciviridae Sapovirus GII')\n",
    "available_genogroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values to 'Unassigned'\n",
    "for i in range(1,5):\n",
    "    genogroup = 'seq %d: Genus / Genogroup'%i\n",
    "    df.loc[df[genogroup].isna(), genogroup] = 'Unassigned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### & Assumption: the following columns store multiple informations, which is alredy stored in another column anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b1495d92890d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#First get rid of the columns that contain a summary of other columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrop_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ORF1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ORF1 variant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ORF2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ORF2 variant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Genus / Genogroup'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#First get rid of the columns that contain a summary of other columns\n",
    "drop_cols = ['ORF1', 'ORF1 variant', 'ORF2', 'ORF2 variant', 'Genus / Genogroup' ]\n",
    "df = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### & Assumption: each seq (1,2,3,4) entry is a different virus\n",
    "We will create a new DataFrame, but each seqX will be in a separate row.\n",
    "\n",
    "For that we need to determine, which columns/metadata will be copied along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "copycols = list(df.columns)\n",
    "#print(copycols)\n",
    "copycols = ['User', 'Institute', 'Database ID', 'Country', 'Submission Date','Last Update', 'Outbreak Nr', 'Sample Date', 'Dutch lab Y/N', 'Nosocomial infection Y/N (sampledate > 2days after date of hospitalization)', 'Outbreak or sporadic case O/S',\n",
    " 'Source of the sample', 'Specify source', 'Specify animal', 'Suspected country of infection', 'Date of first disease', 'Geo-coded location', 'Suspected mode of transmission',\n",
    " 'Specify other mode of transmission', 'Food item', 'Specify food item', 'Setting of the outbreak', 'Specify setting', 'Point source transmission Y/N', 'Date of point source transmission',\n",
    " 'Nr of persons affected', 'Nr of persons at risk', 'Nr of cases deceased', 'Nr of cases hospitalized due to infection', 'Nr of cases of ages 0 to 4', 'Nr of cases of ages 5 to 14',\n",
    " 'Nr of cases of ages 15 to 64', 'Nr of cases of age 65 or older', 'Nr of cases with vomiting', 'Nr of cases with diarrhea', 'Nr of cases with vomiting AND diarrhea',\n",
    " 'Mixed infection Y/N', 'Specify other pathogen(s)', 'Nr of samples tested', 'Nr of PCR positive samples', 'Nr of PCR negative samples', 'Included in II.4 P2 capsid surveillance',\n",
    " 'fasta_id', 'reference_id', 'fragment_begin', 'Genus-Genogroup', 'ORF1', 'ORF1_variant', 'ORF2', 'ORF2_variant', 'Reference_sequence_for_positions', 'Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs = []\n",
    "for si in range(1,5):\n",
    "    rename_dict = {'seq %d: fasta id'%(si): 'fasta_id',\n",
    "                   'seq %d: reference id'%(si): 'reference_id',\n",
    "                   'seq %d: fragment begin'%(si): 'fragment_begin',\n",
    "                   'seq %d: fragment end'%(si): 'fragment_end',\n",
    "                   'seq %d: Genus / Genogroup'%(si): 'Genus-Genogroup',\n",
    "                   'seq %d: ORF1'%(si): 'ORF1',\n",
    "                   'seq %d: ORF1 variant'%(si): 'ORF1_variant',\n",
    "                   'seq %d: ORF2'%(si): 'ORF2',\n",
    "                   'seq %d: ORF2 variant'%(si): 'ORF2_variant',\n",
    "                   'seq %d: Reference sequence for positions'%(si): 'Reference_sequence_for_positions',\n",
    "                   'seq %d: Cluster'%(si): 'Cluster'}\n",
    "    tdfs.append(df.rename(rename_dict, axis=1)[copycols])\n",
    "#     for ir, r in tdf.iterrows():\n",
    "#         gengroup = 'Genus-Genogroup'\n",
    "#         if r[gengroup] in available_genogroups:\n",
    "#             ndf.append(r, ignore_index=True)\n",
    "\n",
    "ndf = pd.concat(tdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82912, 52)\n",
      "(82912, 52)\n",
      "(56586, 52)\n"
     ]
    }
   ],
   "source": [
    "print(ndf.shape)\n",
    "ndf = ndf[ndf['Genus-Genogroup'].notna()]\n",
    "ndf = ndf.reset_index(level=0, drop=True)\n",
    "print(ndf.shape)\n",
    "print(ndf[ndf['Genus-Genogroup']=='Unassigned'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "* drop columns with irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get rid of columns with no value at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column: Nosocomial infection Y/N (sampledate > 2days after date of hospitalization)\n"
     ]
    }
   ],
   "source": [
    "for c in ndf.columns:\n",
    "    if ndf[c].notna().sum()==0:\n",
    "        print(\"Dropping column: %s\"%c)\n",
    "        ndf.drop(c, axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check relevancy\n",
    "drop_irrelevant_cols = ['Dutch lab Y/N',  'Nr of cases with vomiting AND diarrhea']\n",
    "ndf.drop(drop_irrelevant_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks better this way\n",
    "colname = 'Suspected country of infection'\n",
    "ndf.loc[ndf[colname]=='Same as reporting country', colname] = ndf.loc[ndf[colname]=='Same as reporting country', 'Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological beackground for the meaning and categorization of the Open Reading Frames (ORF)\n",
    "\n",
    "From https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3371806/\n",
    "``` \n",
    "Noroviruses (NoV) are divided into 5 genogroups (I–V) based on genome sequence (1). NoV genogroups I and II (GI and GII) are now recognized as the predominant worldwide cause of outbreaks of acute gastroenteritis in humans (2,3). NoV are small round virions 27–35 nm in diameter and possess a single-stranded, positive-sense RNA genome of 7.5 to 7.7 kb. The genome includes 3 overlapping open reading frames (ORFs) (4). The first ORF (ORF1) encodes a polypeptide with regions of similarity to helicase, cysteine proteinase, and RNA-dependent RNA polymerase (RdRp)-encoding regions of picornaviruses (5). ORF2 encodes a viral capsid protein (VP1), and ORF3 encodes a minor structural protein (VP2) associated with VP1 stability (6).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ndf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf9e3e164be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mndf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ndf' is not defined"
     ]
    }
   ],
   "source": [
    "ndf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split ORFs into genogroup and genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'GII.P7', 'GII.P4', 'GII.Pa', 'GII.P3', 'GII.P1', 'GII.P12',\n",
       "       'GII.P2', 'GI.Pb', 'Could not assign', 'GI.P2', 'GII.P5', 'GI.P4',\n",
       "       'GI.P3', 'GII.Pg', 'GII.P6', 'GII.Pf', 'GII.P21', 'GII.Ph',\n",
       "       'GI.P5', 'GII.P16', 'GII.Pr', 'GII.P8', 'GII.Pj', 'GII.Pe',\n",
       "       'GI.P7', 'GII.P13', 'GI.Pd', 'GI.Pa', 'GI.P1', 'GI.Pf', 'GII.P22',\n",
       "       'GI.P9', 'GII.P17', 'GI.P6', 'GII.Pm', 'GI.P8', 'GII.P20',\n",
       "       'GII.Pc', 'GII.Pq', 'GII.P11', 'GII.P30 (GII.Pc)',\n",
       "       'GI.P13 (GI.Pd)', 'GII.P31 (GII.Pe)', 'GI.P14 (GI.Pf)',\n",
       "       'GII.P21 (GII.Pb)', 'GI.P11 (GI.Pb)', 'GII.P15'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf['ORF1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### & Assumption: For these below we use the one in the bracket\n",
    "'GII.P30 (GII.Pc)'\n",
    "'GI.P13 (GI.Pd)'\n",
    "'GII.P31 (GII.Pe)'\n",
    "'GI.P14 (GI.Pf)'\n",
    "'GII.P21 (GII.Pb)'\n",
    "'GI.P11 (GI.Pb)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.loc[ndf['ORF1']=='Could not assign', 'ORF1'] = 'Unknown'\n",
    "ndf.loc[ndf['ORF2']=='Could not assign', 'ORF2'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['ORF1_genotype'] = ndf['ORF1'].apply(lambda x: x.split(\".\")[-1] if type(x) != np.float else 'Unknown')\n",
    "ndf['ORF1_genogroup'] = ndf['ORF1'].apply(lambda x: x.split(\".\")[0] if type(x) != np.float else 'Unknown')\n",
    "ndf['ORF2_genotype'] = ndf['ORF2'].apply(lambda x: x.split(\".\")[-1] if type(x) != np.float else 'Unknown')\n",
    "ndf['ORF2_genogroup'] = ndf['ORF2'].apply(lambda x: x.split(\".\")[0] if type(x) != np.float else 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Typos\n",
    "ndf.loc[ndf['ORF1_genotype']=='Pb)', 'ORF1_genotype'] = 'Pb'\n",
    "ndf.loc[ndf['ORF1_genotype']=='Pc)', 'ORF1_genotype'] = 'Pc'\n",
    "ndf.loc[ndf['ORF1_genotype']=='Pd)', 'ORF1_genotype'] = 'Pd'\n",
    "ndf.loc[ndf['ORF1_genotype']=='Pe)', 'ORF1_genotype'] = 'Pe'\n",
    "ndf.loc[ndf['ORF1_genotype']=='Pf)', 'ORF1_genotype'] = 'Pf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out columns depending on their type of data\n",
    "* with boolean (e.g. yes/no)\n",
    "* with only strings\n",
    "* with few integers\n",
    "* with a range of numbers\n",
    "* with datetime data\n",
    "\n",
    "Then we could put columns with fewer unique values in the columns of the pivottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans = ['Outbreak or sporadic case O/S', 'Point source transmission Y/N', 'Mixed infection Y/N', 'Included in II.4 P2 capsid surveillance']\n",
    "numbers = [ 'Nr of persons affected', 'Nr of persons at risk', 'Nr of cases deceased', 'Nr of cases hospitalized due to infection', 'Nr of cases of ages 0 to 4',\n",
    "           'Nr of cases of ages 5 to 14', 'Nr of cases of ages 15 to 64', 'Nr of cases of age 65 or older', 'Nr of cases with vomiting', 'Nr of cases with diarrhea',\n",
    "            'Nr of samples tested', 'Nr of PCR positive samples', 'Nr of PCR negative samples']\n",
    "geo = [ 'Institute', 'Country', 'Suspected country of infection']\n",
    "dates = ['Submission Date', 'Last Update', 'Sample Date','Date of first disease','Date of point source transmission',]\n",
    "ids = ['User', 'Database ID', 'Outbreak Nr']\n",
    "pathological = ['Source of the sample', 'Specify source', 'Suspected mode of transmission', 'Specify other mode of transmission', 'Food item', 'Specify food item',\n",
    " 'Setting of the outbreak', 'Specify setting', 'Specify other pathogen(s)']\n",
    "seq_data =['fasta_id', 'reference_id', 'fragment_begin', 'Genus-Genogroup', 'ORF1_genogroup', 'ORF1_genotype', 'ORF1_variant', 'ORF2_genogroup', 'ORF2_genotype', 'ORF2_variant', 'Reference_sequence_for_positions', 'Cluster']\n",
    "etc = ['Geo-coded location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert some columns into categorycal type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Country', 'ORF1_genogroup', 'ORF2_genogroup', 'ORF1_genotype', 'ORF2_genotype', 'Genus-Genogroup', 'Setting of the outbreak']:\n",
    "    ndf[c] = ndf[c].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Submission Date',\n",
       " 'Last Update',\n",
       " 'Sample Date',\n",
       " 'Date of first disease',\n",
       " 'Date of point source transmission']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# a = pd.to_datetime(ndf['Sample Date'], errors='coerce')\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    print(i)\n",
    "    ndf.loc[:, dates[i]] = pd.to_datetime(ndf[dates[i]], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Date of first disease</th>\n",
       "      <th>Date of point source transmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Submission Date Last Update Sample Date Date of first disease  \\\n",
       "0      1992-01-01         NaT  1992-01-01            1992-01-01   \n",
       "1      1994-01-01         NaT  1994-01-01            1994-01-01   \n",
       "2      1994-01-01         NaT  1994-01-01            1994-01-01   \n",
       "3      1997-01-01         NaT  1997-01-01            1997-01-01   \n",
       "4      1997-01-01         NaT  1997-01-01            1997-01-01   \n",
       "\n",
       "  Date of point source transmission  \n",
       "0                               NaT  \n",
       "1                               NaT  \n",
       "2                               NaT  \n",
       "3                               NaT  \n",
       "4                               NaT  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf[dates].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = ndf[ndf['Sample Date'].notna()]\n",
    "# reindex entries\n",
    "ndf = ndf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "#output = \"noronet_clean.fr\"\n",
    "output = \"noronet_all_clean.fr\"\n",
    "#output_categories = \"categories.json\"\n",
    "output_categories = \"categories_all.json\"\n",
    "ndf.to_feather(output)\n",
    "\n",
    "# categories\n",
    "dict_categories = {'geo':geo,\n",
    "                  'booleans':booleans,\n",
    "                  'numbers': numbers,\n",
    "                  'dates': dates,\n",
    "                   'ids': ids,\n",
    "                   'pathological': pathological,\n",
    "                   'seq_data': seq_data,\n",
    "                   'etc': etc\n",
    "                  }\n",
    "\n",
    "with open(output_categories, 'w') as f:\n",
    "    f.write(json.dumps(dict_categories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see each categories in detail, and check if we didn't miss any detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'S' nan]\n",
      "[nan 'No' 'Yes']\n",
      "[nan 'No' 'Yes']\n",
      "[nan 'Yes' 'No']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                   Non-Null Count  Dtype \n",
      "---  ------                                   --------------  ----- \n",
      " 0   Outbreak or sporadic case O/S            56752 non-null  object\n",
      " 1   Point source transmission Y/N            31332 non-null  object\n",
      " 2   Mixed infection Y/N                      39852 non-null  object\n",
      " 3   Included in II.4 P2 capsid surveillance  12032 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#booleans\n",
    "for c in booleans:\n",
    "    print(ndf[c].unique())\n",
    "ndf[booleans].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for each column\n",
      "Nr of persons affected \t 276\n",
      "Nr of persons at risk \t 548\n",
      "Nr of cases deceased \t 30\n",
      "Nr of cases hospitalized due to infection \t 74\n",
      "Nr of cases of ages 0 to 4 \t 52\n",
      "Nr of cases of ages 5 to 14 \t 97\n",
      "Nr of cases of ages 15 to 64 \t 105\n",
      "Nr of cases of age 65 or older \t 128\n",
      "Nr of cases with vomiting \t 96\n",
      "Nr of cases with diarrhea \t 103\n",
      "Nr of samples tested \t 79\n",
      "Nr of PCR positive samples \t 59\n",
      "Nr of PCR negative samples \t 56\n",
      "\n",
      "Informations about the numbers category\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 13 columns):\n",
      " #   Column                                     Non-Null Count  Dtype \n",
      "---  ------                                     --------------  ----- \n",
      " 0   Nr of persons affected                     21236 non-null  object\n",
      " 1   Nr of persons at risk                      11620 non-null  object\n",
      " 2   Nr of cases deceased                       9044 non-null   object\n",
      " 3   Nr of cases hospitalized due to infection  10628 non-null  object\n",
      " 4   Nr of cases of ages 0 to 4                 3464 non-null   object\n",
      " 5   Nr of cases of ages 5 to 14                3380 non-null   object\n",
      " 6   Nr of cases of ages 15 to 64               6324 non-null   object\n",
      " 7   Nr of cases of age 65 or older             6588 non-null   object\n",
      " 8   Nr of cases with vomiting                  5584 non-null   object\n",
      " 9   Nr of cases with diarrhea                  5856 non-null   object\n",
      " 10  Nr of samples tested                       20976 non-null  object\n",
      " 11  Nr of PCR positive samples                 28528 non-null  object\n",
      " 12  Nr of PCR negative samples                 24464 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#numbers\n",
    "dict_numbers_unique_values = { c: len(ndf[c].unique()) for c in numbers}\n",
    "print(\"Number of unique values for each column\")\n",
    "for k in dict_numbers_unique_values.keys():\n",
    "    print(k, \"\\t\",dict_numbers_unique_values[k])\n",
    "\n",
    "print(\"\\nInformations about the numbers category\")\n",
    "ndf[numbers].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for each column\n",
      "Institute \t 43\n",
      "Country \t 24\n",
      "Suspected country of infection \t 29\n",
      "\n",
      "Informations about the geo data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 3 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   Institute                       82900 non-null  object  \n",
      " 1   Country                         82900 non-null  category\n",
      " 2   Suspected country of infection  75908 non-null  object  \n",
      "dtypes: category(1), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#geo\n",
    "dict_unique_values = { c: len(ndf[c].unique()) for c in geo}\n",
    "print(\"Number of unique values for each column\")\n",
    "for k in dict_unique_values.keys():\n",
    "    print(k, \"\\t\",dict_unique_values[k])\n",
    "\n",
    "print(\"\\nInformations about the geo data\")\n",
    "ndf[geo].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for each column\n",
      "Submission Date \t 1852\n",
      "Last Update \t 7189\n",
      "Sample Date \t 4480\n",
      "Date of first disease \t 3456\n",
      "Date of point source transmission \t 247\n",
      "\n",
      "Informations about the numbers category\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 5 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   Submission Date                    82900 non-null  datetime64[ns]\n",
      " 1   Last Update                        28776 non-null  datetime64[ns]\n",
      " 2   Sample Date                        82900 non-null  datetime64[ns]\n",
      " 3   Date of first disease              42320 non-null  datetime64[ns]\n",
      " 4   Date of point source transmission  1104 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](5)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "#dates\n",
    "dict_unique_values = { c: len(ndf[c].unique()) for c in dates}\n",
    "print(\"Number of unique values for each column\")\n",
    "for k in dict_unique_values.keys():\n",
    "    print(k, \"\\t\",dict_unique_values[k])\n",
    "\n",
    "print(\"\\nInformations about the numbers category\")\n",
    "ndf[dates].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for each column\n",
      "Source of the sample \t 6\n",
      "Specify source \t 28\n",
      "Suspected mode of transmission \t 7\n",
      "Specify other mode of transmission \t 82\n",
      "Food item \t 10\n",
      "Specify food item \t 185\n",
      "Setting of the outbreak \t 12\n",
      "Specify setting \t 695\n",
      "Specify other pathogen(s) \t 111\n",
      "\n",
      "Informations about the pathological category\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 9 columns):\n",
      " #   Column                              Non-Null Count  Dtype   \n",
      "---  ------                              --------------  -----   \n",
      " 0   Source of the sample                79640 non-null  object  \n",
      " 1   Specify source                      516 non-null    object  \n",
      " 2   Suspected mode of transmission      36608 non-null  object  \n",
      " 3   Specify other mode of transmission  524 non-null    object  \n",
      " 4   Food item                           2780 non-null   object  \n",
      " 5   Specify food item                   1576 non-null   object  \n",
      " 6   Setting of the outbreak             44772 non-null  category\n",
      " 7   Specify setting                     12212 non-null  object  \n",
      " 8   Specify other pathogen(s)           920 non-null    object  \n",
      "dtypes: category(1), object(8)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#pathological\n",
    "dict_unique_values = { c: len(ndf[c].unique()) for c in pathological}\n",
    "print(\"Number of unique values for each column\")\n",
    "for k in dict_unique_values.keys():\n",
    "    print(k, \"\\t\",dict_unique_values[k])\n",
    "\n",
    "print(\"\\nInformations about the pathological category\")\n",
    "ndf[pathological].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informations about the the sequences\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82900 entries, 0 to 82899\n",
      "Data columns (total 12 columns):\n",
      " #   Column                            Non-Null Count  Dtype   \n",
      "---  ------                            --------------  -----   \n",
      " 0   fasta_id                          26523 non-null  object  \n",
      " 1   reference_id                      25977 non-null  object  \n",
      " 2   fragment_begin                    25977 non-null  float64 \n",
      " 3   Genus-Genogroup                   82900 non-null  category\n",
      " 4   ORF1_genogroup                    82900 non-null  category\n",
      " 5   ORF1_genotype                     82900 non-null  category\n",
      " 6   ORF1_variant                      7704 non-null   object  \n",
      " 7   ORF2_genogroup                    82900 non-null  category\n",
      " 8   ORF2_genotype                     82900 non-null  category\n",
      " 9   ORF2_variant                      6221 non-null   object  \n",
      " 10  Reference_sequence_for_positions  25977 non-null  object  \n",
      " 11  Cluster                           18079 non-null  object  \n",
      "dtypes: category(5), float64(1), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#seq\n",
    "print(\"\\nInformations about the the sequences\")\n",
    "ndf[seq_data].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
